{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from core.RobotLink import *\n",
    "from core.StereoCamera import *\n",
    "from core.ParticleFilter import *\n",
    "from core.probability_functions import *\n",
    "from core.utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import rosbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psm_arm = RobotLink('/home/erie-dvrk/force_sensor_particle_filter/calibration_param/LND_erie.json')\n",
    "cam = StereoCamera('/home/erie-dvrk/force_sensor_particle_filter/calibration_param/camera_calibration_erie_640.yaml', rectify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample data!!\n",
    "bag = rosbag.Bag('/home/erie-dvrk/force_sensor_particle_filter/stationary_camera_2020-06-24-15-49-10-001.bag')\n",
    "\n",
    "ecm_pose_list  = []\n",
    "ecm_pose_ts    = []\n",
    "ecm_joint_list = []\n",
    "ecm_joint_ts   = []\n",
    "psm_joint_list = []\n",
    "psm_joint_ts   = []\n",
    "psm_jaw_list   = []\n",
    "psm_jaw_ts     = []\n",
    "left_img_list  = []\n",
    "left_img_ts    = []\n",
    "right_img_list = []\n",
    "right_img_ts   = []\n",
    "\n",
    "for topic, msg, t in bag.read_messages(topics=['/dvrk/ECM/position_cartesian_current', \n",
    "                                               '/dvrk/ECM/state_joint_current',\n",
    "                                               '/dvrk/PSM1/state_joint_current',\n",
    "                                               '/dvrk/PSM1/state_jaw_current',\n",
    "                                               '/stereo/left/image',\n",
    "                                               '/stereo/right/image']):\n",
    "    if topic == '/dvrk/ECM/position_cartesian_current':\n",
    "        ecm_pose_list.append(msg)\n",
    "        ecm_pose_ts.append(msg.header.stamp.to_sec())\n",
    "    elif topic == '/dvrk/ECM/state_joint_current':\n",
    "        ecm_joint_list.append(msg)\n",
    "        ecm_joint_ts.append(msg.header.stamp.to_sec())\n",
    "    elif topic == '/dvrk/PSM1/state_joint_current':\n",
    "        psm_joint_list.append(msg)\n",
    "        psm_joint_ts.append(msg.header.stamp.to_sec())\n",
    "    elif topic == '/dvrk/PSM1/state_jaw_current':\n",
    "        psm_jaw_list.append(msg)\n",
    "        psm_jaw_ts.append(msg.header.stamp.to_sec())\n",
    "    elif topic == '/stereo/left/image':\n",
    "        left_img_list.append(msg)\n",
    "        left_img_ts.append(msg.header.stamp.to_sec())\n",
    "    elif topic == '/stereo/right/image':\n",
    "        right_img_list.append(msg)\n",
    "        right_img_ts.append(msg.header.stamp.to_sec())\n",
    "\n",
    "bag.close()\n",
    "\n",
    "ecm_pose_ts  = np.array(ecm_pose_ts)\n",
    "ecm_joint_ts = np.array(ecm_joint_ts)\n",
    "psm_joint_ts = np.array(psm_joint_ts)\n",
    "psm_jaw_ts   = np.array(psm_jaw_ts)\n",
    "left_img_ts  = np.array(left_img_ts)\n",
    "right_img_ts = np.array(right_img_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hand-eye transform (this will be hard-coded for now according to the dataset)\n",
    "f = open('/home/erie-dvrk/force_sensor_particle_filter/calibration_param/handeye_erie.yaml')\n",
    "hand_eye_data = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_T_cam = np.eye(4)\n",
    "# bc_T_cam[:-1, -1] = np.array(hand_eye_data['cam_tvec']).reshape(-1)/1000.0\n",
    "# bc_T_cam[:-1, :-1] = axisAngleToRotationMatrix(hand_eye_data['cam_rvec'])\n",
    "cam_T_b = np.eye(4)\n",
    "cam_T_b[:-1, -1] = np.array(hand_eye_data['PSM1_tvec']).reshape(-1)/1000.0\n",
    "cam_T_b[:-1, :-1] = axisAngleToRotationMatrix(hand_eye_data['PSM1_rvec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize filter\n",
    "pf = ParticleFilter(num_states=9, \n",
    "                    initialDistributionFunc=sampleNormalDistribution,\n",
    "                    #motionModelFunc=additiveGaussianNoise, \n",
    "                    motionModelFunc=lumpedErrorMotionModel,\n",
    "                    obsModelFunc=pointFeatureObs,\n",
    "                    num_particles=200)\n",
    "\n",
    "initalize = True\n",
    "\n",
    "# output video\n",
    "left_video  = cv2.VideoWriter(\"left_video.mp4\",  cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 30, cam.img_size)\n",
    "right_video = cv2.VideoWriter(\"right_video.mp4\", cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 30, cam.img_size)\n",
    "\n",
    "for left_msg_idx, left_img_msg in enumerate(left_img_list):\n",
    "    \n",
    "    # Synchronize the data to the left_img_msg\n",
    "    ts = left_img_ts[left_msg_idx]\n",
    "\n",
    "    ecm_pose_msg  = ecm_pose_list[np.argmin(np.abs(ecm_pose_ts - ts))]\n",
    "    ecm_joint_msg = ecm_joint_list[np.argmin(np.abs(ecm_joint_ts - ts))]\n",
    "    psm_joint_msg = psm_joint_list[np.argmin(np.abs(psm_joint_ts - ts))]\n",
    "    psm_jaw_msg   = psm_jaw_list  [np.argmin(np.abs(psm_jaw_ts - ts))]\n",
    "    right_img_msg = right_img_list[np.argmin(np.abs(right_img_ts - ts))]\n",
    "    \n",
    "    try:\n",
    "        left_img  = np.ndarray(shape=(left_img_msg.height, left_img_msg.width, 3),\n",
    "                                      dtype=np.uint8, buffer=left_img_msg.data)\n",
    "        right_img = np.ndarray(shape=(right_img_msg.height, right_img_msg.width, 3),\n",
    "                                      dtype=np.uint8, buffer=right_img_msg.data)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    left_img, right_img = cam.processImage(left_img, right_img)\n",
    "    \n",
    "    # Detect segmented keypoints and get new joint angle readings\n",
    "    detected_keypoints_l, left_img  = segmentColorAndGetKeyPoints(left_img,  draw_contours=True)\n",
    "    detected_keypoints_r, right_img = segmentColorAndGetKeyPoints(right_img, draw_contours=True)\n",
    "    new_joint_angles = np.array(psm_joint_msg.position + psm_jaw_msg.position)\n",
    "    # new_joint_angles[6] = new_joint_angles[6] - 1.3934\n",
    "\n",
    "    start_t = time.time()\n",
    "    psm_arm.updateJointAngles(new_joint_angles)\n",
    "    \n",
    "    if initalize:\n",
    "        # Initialize particle filter\n",
    "        initalize = False\n",
    "        \n",
    "        init_kwargs = {\n",
    "                        \"std\": np.array([1.0e-3, 1.0e-3, 1.0e-3, # pos\n",
    "                                         1.0e-2, 1.0e-2, 1.0e-2, # ori\n",
    "                                         #5.0e-3, 5.0e-3, 0.02\n",
    "                                         0.0, 0.0, 0.0])   # joints\n",
    "                      }\n",
    "        pf.initializeFilter(**init_kwargs)\n",
    "\n",
    "    else:\n",
    "        # Predict particle filter\n",
    "        j_change = new_joint_angles - last_joint_angle_reading\n",
    "\n",
    "        std_j = np.abs(j_change)*0.01\n",
    "        std_j[-3:] = 0.0\n",
    "        \n",
    "        pred_kwargs = {\n",
    "                        \"std_pos\": 2.5e-5, \n",
    "                        \"std_ori\": 1.0e-4,\n",
    "                        \"robot_arm\": psm_arm, \n",
    "                        \"std_j\": std_j,\n",
    "                        \"nb\": 4\n",
    "                      }\n",
    "        pf.predictionStep(**pred_kwargs)\n",
    "    \n",
    "    # Update particle filter\n",
    "    upd_kwargs = {\n",
    "                    \"point_detections\": (detected_keypoints_l, detected_keypoints_r), \n",
    "                    \"robot_arm\": psm_arm, \n",
    "                    \"cam\": cam, \n",
    "                    \"cam_T_b\": cam_T_b,\n",
    "                    \"joint_angle_readings\": new_joint_angles,\n",
    "                    \"gamma\": 0.15\n",
    "    }\n",
    "    \n",
    "    pf.updateStep(**upd_kwargs)\n",
    "    last_joint_angle_reading = new_joint_angles\n",
    "    \n",
    "    correction_estimation = pf.getMeanParticle()\n",
    "    \n",
    "    print(\"Time to update robot: {}ms\".format((time.time()-start_t)*1000))\n",
    "    \n",
    "    # Project skeleton\n",
    "    T = poseToMatrix(correction_estimation[:6])  \n",
    "    new_joint_angles[-(correction_estimation.shape[0]-6):] += correction_estimation[6:]\n",
    "    psm_arm.updateJointAngles(new_joint_angles)\n",
    "    img_list = projectSkeleton(psm_arm.getSkeletonPoints(), np.dot(cam_T_b, T), [left_img, right_img], cam.projectPoints)\n",
    "    \n",
    "    left_video.write(img_list[0])\n",
    "    right_video.write(img_list[1])\n",
    "    \n",
    "left_video.release()\n",
    "right_video.release()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a91e487c0038294e5f05cb0221d4915556ffca28efce0deb107779923acf538"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
